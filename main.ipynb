{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica Bloque 2 - IA\n",
    "\n",
    "Autores: Sergi Mayol Matos, Alejandro Rodríguez Arguimbau <br>\n",
    "Correos: sergi.mayol1@estudiant.uib.cat, alejandro.rodriguez7@estudiant.uib.cat <br>\n",
    "Fecha: 06/12/2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerrequisitos\n",
    "\n",
    "Para los siguientes apartados ([parte 1](#parte-1-preparación-de-los-datos) y [parte 2]()) se emplearán las siguientes librerías:\n",
    "\n",
    "* [numpy](https://numpy.org/)\n",
    "* [pandas](https://pandas.pydata.org/)\n",
    "* [matplotlib](https://matplotlib.org/)\n",
    "* [sklearn](https://scikit-learn.org/stable/)\n",
    "\n",
    "> Nota: Para ver más información sobre las librerías, mirar el fichero [Pipfile](./Pipfile).\n",
    "\n",
    "### Instalación de librerías\n",
    "\n",
    "Para instalar las librerías, se debe ejecutar el siguiente comando:\n",
    "\n",
    "```bash\n",
    "pipenv install -d\n",
    "```\n",
    "\n",
    "> Nota: Se necesita tener instalado [pipenv](https://pypi.org/project/pipenv/).\n",
    "\n",
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Entrenamiento de modelos y comparación de resultados \n",
    "\n",
    "En la primera parte de la práctica se entrenarán diferentes modelos de clasificación (Regrsión lineal, Perceptrón, Random Forest) y se compararán sus resultados.\n",
    "\n",
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datos/dades.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis y procesamiento de datos\n",
    "\n",
    "En esta sección se analizarán los datos de entrada para ver si hay que eliminar o modificar algún dato.\n",
    "\n",
    "Para analizar los datos, comprobaremos la cantidad de datos que faltan en cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_is_nan(df: pd.DataFrame):\n",
    "    results = []\n",
    "    col_names = []\n",
    "    for col in df.columns:\n",
    "        col_names.append(col)\n",
    "        results.append(df[col].isna().sum())\n",
    "\n",
    "    return {\"col_names\": col_names, \"results\": results, \"percent\": [x/len(df) for x in results]}\n",
    "\n",
    "\n",
    "results = check_is_nan(df)\n",
    "\n",
    "for i in range(len(results[\"col_names\"])):\n",
    "    print(\n",
    "        f\"{results['col_names'][i]}: {results['results'][i]} ({results['percent'][i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(results[\"col_names\"], results[\"percent\"])\n",
    "plt.title(\"Porcentaje de valores nulos por columna\")\n",
    "plt.xlabel(\"Columnas\")\n",
    "plt.ylabel(\"Porcentaje\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede observar que existen 3 columnas con datos inexistentes:\n",
    "\n",
    "* `Age`\n",
    "* `Cabin`\n",
    "* `Embarked`\n",
    "\n",
    "Aunque de las 3 columnas, la columna con más datos faltantes, con diferencia, es `Cabin`, casi un 80%. Por ello, se eliminará esta columna.\n",
    "\n",
    "Por lo que los datos que quedan, de momento, son:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Cabin'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las columnas `Age` y `Embarked`, se rellenarán los datos faltantes con la media y la moda, respectivamente. Se realizará la media de `Age`, ya que faltan aproximadamente un **20%** de los datos, y la moda de `Embarked`, ya que faltan muy pocos datos y no son datos numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "media_edad = df[\"Age\"].mean()\n",
    "df[\"Age\"].fillna(media_edad, inplace=True)\n",
    "\n",
    "moda_embarque = df[\"Embarked\"].mode()[0]\n",
    "df[\"Embarked\"].fillna(moda_embarque, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso las columnas `Name` y `Ticket` no las vamos a utilizar y por eso las eliminamos del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['Name'], axis=1, inplace=True)\n",
    "#df.drop(['Ticket'], axis=1, inplace=True)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convertimos la columna `Sex` en 0 y 1:\n",
    "* Hombres: 0\n",
    "* Mujeres: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex']=df['Sex'].replace('male', 0)\n",
    "df['Sex']=df['Sex'].replace('female', 1)\n",
    "#clb = df.pop(\"Sex\")\n",
    "#ohe_clb = pd.get_dummies(clb, prefix='Sex')\n",
    "#df = pd.concat([df.reset_index(drop=True), ohe_clb.reset_index(drop=True)], axis=1, sort=False)\n",
    "df.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos el tamaño de cada familia y la añadimos al conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "# One-hot encoding para la columna Embarked\n",
    "clb = df.pop(\"Embarked\")\n",
    "ohe_clb = pd.get_dummies(clb, prefix='Embarked')\n",
    "df = pd.concat([df.reset_index(drop=True), ohe_clb.reset_index(drop=True)], axis=1, sort=False)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se puede dividir la columna `Age` en 5 grupos:\n",
    "* 0-12  $\\rightarrow$ Niños\n",
    "* 13-17 $\\rightarrow$ Adolescentes\n",
    "* 18-45 $\\rightarrow$ Adultos\n",
    "* 46-64 $\\rightarrow$ Adultos mayores\n",
    "* 65+   $\\rightarrow$ Ancianos\n",
    "\n",
    "Además, se puede dividir la columna `Fare` en 4 grupos:\n",
    "* 0-7.91   $\\rightarrow$ Bajo\n",
    "* 7.91-14.45 $\\rightarrow$ Medio\n",
    "* 14.45-31 $\\rightarrow$ Alto\n",
    "* 31+      $\\rightarrow$ Muy alto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get max value of the column 'Fare'\n",
    "max_value = df['Fare'].max()\n",
    "# get max value of the column 'Age'\n",
    "max_value_age = df['Age'].max()\n",
    "\n",
    "print(max_value)\n",
    "print(max_value_age)\n",
    "\n",
    "for age in df:\n",
    "    df['Age_type'] = pd.cut(df['Age'], bins=[0, 13, 18, 45, 65, 120], labels=['Child', 'Teenager', 'Adult', 'Senior', 'Elderly'])\n",
    "\n",
    "for fare in df:\n",
    "    df['Fare_type'] = pd.cut(df['Fare'], bins=[0, 7.91, 14.454, 31, 120], labels=['Low_fare', 'median_fare', 'Average_fare', 'high_fare'])\n",
    "\n",
    "df.drop(['Age'], axis=1, inplace=True)\n",
    "df.drop(['Fare'], axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encoding para la columna Age_type \n",
    "clb = df.pop(\"Age_type\")\n",
    "ohe_clb = pd.get_dummies(clb, prefix='Age')\n",
    "df = pd.concat([df.reset_index(drop=True), ohe_clb.reset_index(drop=True)], axis=1, sort=False)\n",
    "\n",
    "# One-hot encoding para la columna Fare_type\n",
    "clb = df.pop(\"Fare_type\")\n",
    "ohe_clb = pd.get_dummies(clb, prefix='Fare')\n",
    "df = pd.concat([df.reset_index(drop=True), ohe_clb.reset_index(drop=True)], axis=1, sort=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza la matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que las columnas `Sex` y `Survived` tienen una correlación de 0.54, por lo que se puede decir que hay una relación entre la supervivencia y el sexo. También, se observa que `Parch` y `SibSp` ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(['SibSp'], axis=1, inplace=True)\n",
    "#df.drop(['Parch'], axis=1, inplace=True)\n",
    "df.drop(['PassengerId'], axis=1, inplace=True)\n",
    "df.drop(['Name'], axis=1, inplace=True)\n",
    "df.drop(['Ticket'], axis=1, inplace=True)\n",
    "# Las columnas de embarque no aportan nada a la predicción, por lo que las eliminamos\n",
    "#df.drop(['Embarked_C'], axis=1, inplace=True)\n",
    "#df.drop(['Embarked_Q'], axis=1, inplace=True)\n",
    "#df.drop(['Embarked_S'], axis=1, inplace=True)\n",
    "\n",
    "corr = df.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.pairplot(data=df, hue='Survived', palette = 'seismic',\n",
    "                 size=1.2,diag_kind = 'kde',diag_kws=dict(shade=True),plot_kws=dict(s=10) )\n",
    "g.set(xticklabels=[])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, mean_absolute_error, mean_squared_error,\n",
    "                             classification_report)\n",
    "\n",
    "training_ds = df.drop(['Survived'], axis=1)\n",
    "target_ds = df['Survived']\n",
    "\n",
    "# Dividimos el dataset en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    training_ds, target_ds, test_size=0.33, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regresión logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "\n",
    "log_y_pred = logisticRegr.predict(X_test)\n",
    "\n",
    "print(\"Classification report: \\n\", classification_report(y_test, log_y_pred))\n",
    "\n",
    "# Matriz de confusión\n",
    "sns.heatmap(confusion_matrix(y_test, log_y_pred),\n",
    "            annot=True, fmt=\"3.0f\", cmap='coolwarm')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perceptrón"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "perceptron = Perceptron(tol=1e-3, random_state=42)\n",
    "\n",
    "perceptron.fit(X_train, y_train)\n",
    "\n",
    "#x_intercept = -perceptron.intercept_[0] / perceptron.coef_[0][0]\n",
    "x_intercept = (0, -perceptron.intercept_[0] / perceptron.coef_[0][0])\n",
    "y_intercept = (-perceptron.intercept_[0] / perceptron.coef_[0][0], 0)\n",
    "\n",
    "plt.plot(x_intercept, y_intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percep_y_pred = perceptron.predict(X_test)\n",
    "\n",
    "print(\"Classification report: \\n\", classification_report(y_test, percep_y_pred))\n",
    "\n",
    "# Plot the data, the prediction and the dividing line\n",
    "# plt.scatter(X_test['Sex'], y_test, c=pred, cmap='coolwarm')\n",
    "\n",
    "# plt.plot(x_intercept, y_intercept)\n",
    "sns.heatmap(confusion_matrix(y_test, percep_y_pred),\n",
    "            annot=True, fmt=\"3.0f\", cmap='coolwarm')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Árbol de decisión - Random Forest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que determinar los mejores párametros para el modelo. Para ello, se empleará la función `GridSearchCV` de la librería `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search\n",
    "param_grid = {\n",
    "    'bootstrap': [True, False],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'min_samples_leaf': [1, 2, 3, 4],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 500, 700, 1000],\n",
    "}\n",
    "\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid,\n",
    "                           cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "result = grid_search.best_params_\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se han obtenido los mejores parámetros, se entrena el modelo con estos parámetros. Y se obtiene la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=result['bootstrap'], max_depth=result['max_depth'],\n",
    "                            min_samples_leaf=result['min_samples_leaf'], min_samples_split=result['min_samples_split'],\n",
    "                            n_estimators=result['n_estimators'])\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Classification report: \\n\", classification_report(y_test, rf_y_pred))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y se obtiene la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de confusión\n",
    "sns.heatmap(confusion_matrix(y_test, rf_y_pred),\n",
    "            annot=True, fmt=\"3.0f\", cmap='coolwarm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación y comparción de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelos = pd.DataFrame({\n",
    "    'Modelo': ['Regresión Logística', 'Perceptrón', 'Random Forest'],\n",
    "    'Score': [round(accuracy_score(y_test, log_y_pred), 2), round(accuracy_score(y_test, percep_y_pred), 2), round(accuracy_score(y_test, rf_y_pred), 2)],\n",
    "    'Precision': [round(precision_score(y_test, log_y_pred), 2), round(precision_score(y_test, percep_y_pred), 2), round(precision_score(y_test, rf_y_pred), 2)],\n",
    "    'Recall': [round(recall_score(y_test, log_y_pred), 2), round(recall_score(y_test, percep_y_pred), 2), round(recall_score(y_test, rf_y_pred), 2)],\n",
    "    'F1': [round(f1_score(y_test, log_y_pred), 2), round(f1_score(y_test, percep_y_pred), 2), round(f1_score(y_test, rf_y_pred), 2)],\n",
    "    'MAE': [round(mean_absolute_error(y_test, log_y_pred), 2), round(mean_absolute_error(y_test, percep_y_pred), 2), round(mean_absolute_error(y_test, rf_y_pred), 2)],\n",
    "    'MSE': [round(mean_squared_error(y_test, log_y_pred), 2), round(mean_squared_error(y_test, percep_y_pred), 2), round(mean_squared_error(y_test, rf_y_pred), 2)]\n",
    "})\n",
    "\n",
    "modelos.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Importancia y selección de características"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo se basará en características como el nombre de los pasajeros, el sexo o la edad. Para la realización de los modelos se ha hecho una selección de estas características.\n",
    "\n",
    "La importancia de una característica viene determinada por el valor que esta proporciona al conjunto de datos. \n",
    "\n",
    "Por ejemplo: las columnas Name y Ticket no nos proporcionan ningún valor útil al conjunto de datos y por ello, se han eliminado y no se han tenido en cuenta. \n",
    "\n",
    "En este apartado, se analizará la importancia de cada una de las características para cada modelo de entrenamiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Feature importance Random Forest\n",
    "- Feature importance Regresión Lineal\n",
    "- Feature importance Perceptron\n",
    "- https://machinelearningmastery.com/calculate-feature-importance-with-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature importances for Random Forest:\")\n",
    "importance = rf.feature_importances_\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature importances for Logistic Regression:\")\n",
    "importance = logisticRegr.coef_[0]\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature importances for Perceptron:\")\n",
    "importance = perceptron.coef_[0]\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Selección de los mejores parámetros para cada modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e9f4c2e3c7edcc74941d763c22ae9bb8d5716b7961b59c0906229ce5f7f5dcfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
